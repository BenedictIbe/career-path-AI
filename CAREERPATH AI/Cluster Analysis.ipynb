{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Title**: CLUSTER ANALYSIS\r\n",
        "\r\n",
        "**Description**: Job title categorization of the job history dataset using cluster approach\r\n",
        "\r\n",
        "**Author**: Benedict Ibe\r\n",
        "\r\n",
        "**Date Created**: 18/07/2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "pip install kmodes pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {},
      "source": [
        "#Importation of libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "import os\n",
        "os.environ[\"OMP_NUM_THREADS\"] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\n",
        "\n",
        "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
        "candidate_skilllevel= spark.sql(\"SELECT \\\n",
        "Id                                          as Cand_ID, \\\n",
        "recruit_candidatecontact                    as Candidate_contactno, \\\n",
        "crimson_proficiency                         as Cand_proficiency, \\\n",
        "crimson_requirement                         as Cand_requirement, \\\n",
        "crimson_experience                          as Cand_experience, \\\n",
        "crimson_experienceperiod                    as Cand_exp_period, \\\n",
        "crimson_skill                               as Cand_skill, \\\n",
        "crimson_name                                as Cand_name, \\\n",
        "crimson_skilllevelid                        as Cand_skilllevel_ID, \\\n",
        "lower(crimson_skillname)                    as Cand_skill_name, \\\n",
        "crimson_level                               as Cand_level \\\n",
        "FROM dataverse_edensmithcon_org87f26120.crimson_skilllevel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "candidate_skilllevel.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\n",
        "\n",
        "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
        "candidate_workhist =spark.sql(\"SELECT \\\n",
        "Id                                  as ID , \\\n",
        "recruit_candidatecontact            as Candidate_contact,\\\n",
        "crimson_startdate                   as Candidate_workstrt_date,\\\n",
        "crimson_enddate                     as Candidate_workend_date, \\\n",
        "crimson_workhistoryid               as WorkHistory_ID,\\\n",
        "lower(crimson_description)          as Candidate_work_description,\\\n",
        "crimson_jobtitle                    as Candidate_job_title ,\\\n",
        "crimson_name                        as Cand_workplace \\\n",
        "FROM dataverse_edensmithcon_org87f26120.crimson_workhistory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql.functions import to_date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Convert the start date column to date\n",
        "df_hist = candidate_workhist.withColumn(\"Cnd_start_date\", to_date(\"Candidate_workstrt_date\"))\n",
        "df_hist.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Convert the end date column to date\n",
        "df_hist2 = df_hist.withColumn(\"Cnd_end_date\", to_date(\"Candidate_workend_date\"))\n",
        "df_hist2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Select th e required columns\n",
        "df_hist3 = df_hist2.select('ID', 'WorkHistory_ID', 'Candidate_contact', 'Candidate_job_title', 'Cnd_start_date', 'Cnd_end_date')\n",
        "df_hist3.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import datediff, floor\n",
        "from pyspark.sql.functions import lit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Calculate the number of months\n",
        "df_hist4 = df_hist3.withColumn(\"Duration\", floor((datediff(df_hist3[\"Cnd_end_date\"], df_hist3[\"Cnd_start_date\"]) / 7)/4))\n",
        "df_hist4.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "df_hist4cluster = df_hist4.select('Candidate_job_title', 'Duration')\r\n",
        "df_hist4cluster.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "df_skillCluster = candidate_skilllevel.select('Cand_skill_name', 'Cand_level')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "df_skillCluster.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Drop null or missin gvalues in the skill name column\n",
        "df_skillCluster_clean = df_skillCluster.dropna(subset=[\"Cand_skill_name\"])\n",
        "df_skillCluster_clean.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, Word2Vec\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.sql.functions import col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Tokenize the candidate job title\r\n",
        "tokenizer = Tokenizer(inputCol=\"Candidate_job_title\", outputCol=\"words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Tokenize the skill name column\r\n",
        "tokenizer2 = Tokenizer(inputCol=\"Cand_skill_name\", outputCol=\"words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Transform the candidate history dataset with the tokenized variable\n",
        "df_tokenized = tokenizer.transform(df_hist4cluster)\n",
        "df_tokenized.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Transform the candidate skill dataset with the tokenized variable\n",
        "df_tokenized_skill = tokenizer2.transform(df_skillCluster_clean)\n",
        "df_tokenized_skill.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Embedding the tokenized dataset with word2vec embedder\n",
        "word2Vec = Word2Vec(vectorSize=100, minCount=0, inputCol=\"words\", outputCol=\"features\")\n",
        "model = word2Vec.fit(df_tokenized)\n",
        "df_vectorized = model.transform(df_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Getting the tokenized words whose token values are greater than 0, and are not empty\n",
        "from pyspark.sql.functions import col, size\n",
        "\n",
        "tokenizedSkill_clean = df_tokenized_skill.filter(col(\"words\").isNotNull() & (size(col(\"words\")) > 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Fitting the word2vec embedder to the tokenized skill\n",
        "model_skill = word2Vec.fit(df_tokenized_skill)\n",
        "skill_vectorized = model_skill.transform(df_tokenized_skill)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "df_vectorized.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "skill_vectorized.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "df_vectorized2 = df_vectorized.select('Duration', 'features')\n",
        "df_vectorized2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "skill_vectorized2 = skill_vectorized.select('Cand_skill_name', 'features')\n",
        "skill_vectorized2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Treat null values in the duration column\n",
        "df_vectorized3 = df_vectorized.dropna(subset=[\"Duration\"])\n",
        "df_vectorized3.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To get the value for k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Define the K-range values for the skills vectorized dataframe\n",
        "k_range_skill = range(2, 21)\n",
        "wssse_list_skill = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Define the K-range values for the job history vectorized dataframe\n",
        "k_range = range(2, 21)\n",
        "wssse_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Fitting the K-Means model to the vectorized dataset, and calculating the cost of training along the k-value ranges\n",
        "for k in k_range:\n",
        "    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n",
        "    km_model = kmeans.fit(df_vectorized3)\n",
        "    wssse = km_model.summary.trainingCost\n",
        "    wssse_list.append(wssse)\n",
        "    print(f\"K={k}, WSSSE={wssse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Fitting the K-Means model to the vectorized dataset, and calculating the cost of training along the k-value ranges\n",
        "for k in k_range_skill:\n",
        "    kmeans_skill = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n",
        "    km_model_skill = kmeans.fit(skill_vectorized2)\n",
        "    wssse_skill = km_model.summary.trainingCost\n",
        "    wssse_list_skill.append(wssse_skill)\n",
        "    print(f\"K={k}, WSSSE={wssse_skill}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Plot the k-plot for the range of k-values to get the uptimum value for k\n",
        "plt.plot(k_range, wssse_list, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('WSSSE')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#K plot for the skills dataset\n",
        "plt.plot(k_range_skill, wssse_list_skill, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('WSSSE')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Set the value of k from the k plot to get the clusters\n",
        "KMeans().setK(8).setSeed(1)\n",
        "km_model = kmeans.fit(df_vectorized3)\n",
        "df_clusters = km_model.transform(df_vectorized3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Set the value of k from the k plot to get the clusters\n",
        "KMeans().setK(8).setSeed(1)\n",
        "km_model_skill = kmeans.fit(skill_vectorized2)\n",
        "df_clusters_skill = km_model.transform(skill_vectorized2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Set the value of k from the k plot to get the clusters\n",
        "kmeans = KMeans().setK(8).setInitMode('k-means||').setSeed(100)\n",
        "km_model = kmeans.fit(df_vectorized3)\n",
        "df_clusters2 = km_model.transform(df_vectorized3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Inspect/track the predicted k groups\n",
        "df_clusters_skill2 = df_clusters_skill.select(\"Cand_skill_name\", \"prediction\")\n",
        "df_clusters_skill2.show(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Inspect/track the predicted k groups\n",
        "df_clusters3 = df_clusters2.select(\"Candidate_job_title\", \"prediction\")\n",
        "df_clusters3.show(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Understanding the groups**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "prediction = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "skill_prediction = '10'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Track/Inspect the specific value for one group\n",
        "df_categories = df_clusters3.filter(df_clusters3.prediction == prediction)\n",
        "df_categories.show(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Track/Inspect the specific value for one group\n",
        "df_skill_categories = df_clusters_skill2.filter(df_clusters_skill2.prediction == skill_prediction)\n",
        "df_skill_categories.show(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.ml.feature import PCA\n",
        "from pyspark.sql.functions import col\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "ms_comments": [
          {
            "threadId": "6c897282-c769-4019-b694-90d5ffe375c8",
            "text": "reduce the dimensionality",
            "status": "active",
            "user": {
              "name": "Benedict Ibe",
              "idType": "aad"
            },
            "createdDateUTC": 1691764960450,
            "modifiedDateUTC": 1691764960450,
            "replies": []
          }
        ],
        "ms_comment_ranges": {
          "6c897282-c769-4019-b694-90d5ffe375c8": {
            "text": "df_clusters)",
            "start": {
              "line": 4,
              "column": 34
            },
            "end": {
              "line": 4,
              "column": 46
            }
          }
        }
      },
      "source": [
        "#Reduce the dimensionality using the principal component analysis model (PCA)\n",
        "pca = PCA(k=2, inputCol=\"features\", outputCol=\"pca_features\")\n",
        "pca_model = pca.fit(df_clusters)\n",
        "pca_result = pca_model.transform(df_clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Reduce the dimensionality to two(2) dimensions using the principal component analysis model (PCA)\n",
        "pandas_df = pca_result.select(\"pca_features\", \"prediction\").toPandas()\n",
        "pandas_df['pca_x'] = pandas_df['pca_features'].apply(lambda x: x[0])\n",
        "pandas_df['pca_y'] = pandas_df['pca_features'].apply(lambda x: x[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Plot the clusters in a scatter plot with matplotlib\n",
        "plt.figure(figsize=(10,6))\n",
        "scatter = plt.scatter(pandas_df['pca_x'], pandas_df['pca_y'], c=pandas_df['prediction'], cmap='viridis')\n",
        "plt.title(\"Clusters after PCA\")\n",
        "plt.xlabel(\"Component 2\")\n",
        "plt.colorbar(scatter)\n",
        "plt.show()"
      ]
    }
  ]
}